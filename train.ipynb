{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import dgl\n",
    "import pickle\n",
    "import torch as th\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from collections import defaultdict\n",
    "import torch.nn as nn\n",
    "import dgl.nn.pytorch as dglnn\n",
    "import time\n",
    "from itertools import combinations\n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "from dgl.data.utils import save_graphs\n",
    "from dgl.data.utils import load_graphs\n",
    "from io import StringIO\n",
    "from sklearn.decomposition import PCA\n",
    "from functools import partial\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n"
     ]
    }
   ],
   "source": [
    "manager = multiprocessing.Manager()\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "print(device, 'is available')\n",
    "\n",
    "data = load_graphs(\"./g.bin\")\n",
    "g = data[0][0]\n",
    "# calculate the number of nodes\n",
    "n_genes = g.num_nodes('gene')\n",
    "n_ref_cell = g.num_nodes('ref_cell')\n",
    "n_que_cell = g.num_nodes('que_cell')\n",
    "\n",
    "# calculate the number of edges\n",
    "n_ref_cell_2_gene = g.number_of_edges('ref_cell_2_gene')\n",
    "n_gene_2_ref_cell = g.number_of_edges('gene_2_ref_cell')\n",
    "n_que_cell_2_gene = g.number_of_edges('que_cell_2_gene')\n",
    "n_gene_2_que_cell = g.number_of_edges('gene_2_que_cell')\n",
    "\n",
    "input_feature = 50\n",
    "out_feature = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly generate node embeddings\n",
    "g.nodes['gene'].data['feature'] = torch.randn(n_genes, input_feature)\n",
    "g.nodes['ref_cell'].data['feature'] = torch.randn(n_ref_cell, input_feature)\n",
    "g.nodes['que_cell'].data['feature'] = torch.randn(n_que_cell, input_feature)\n",
    "\n",
    "# # randomly generate edge embeddings\n",
    "# g.edges['ref_cell_2_gene'].data['feature'] = torch.randn(n_ref_cell_2_gene, input_feature)\n",
    "# g.edges['gene_2_ref_cell'].data['feature'] = torch.randn(n_gene_2_ref_cell, input_feature)\n",
    "# g.edges['que_cell_2_gene'].data['feature'] = torch.randn(n_que_cell_2_gene, input_feature)\n",
    "# g.edges['gene_2_que_cell'].data['feature'] = torch.randn(n_gene_2_que_cell, input_feature)\n",
    "\n",
    "# # randomly generate training masks on user nodes and click edges\n",
    "# g.nodes['gene'].data['train_mask'] = torch.zeros(n_genes, dtype=torch.bool).bernoulli(0.6)\n",
    "# g.nodes['ref_cell'].data['train_mask'] = torch.zeros(n_ref_cell, dtype=torch.bool).bernoulli(0.6)\n",
    "# g.nodes['que_cell'].data['train_mask'] = torch.zeros(n_que_cell, dtype=torch.bool).bernoulli(0.6)\n",
    "\n",
    "# g.edges['ref_cell_2_gene'].data['train_mask'] = torch.zeros(n_ref_cell_2_gene, dtype=torch.bool).bernoulli(0.6)\n",
    "# g.edges['gene_2_ref_cell'].data['train_mask'] = torch.zeros(n_gene_2_ref_cell, dtype=torch.bool).bernoulli(0.6)\n",
    "# g.edges['que_cell_2_gene'].data['train_mask'] = torch.zeros(n_que_cell_2_gene, dtype=torch.bool).bernoulli(0.6)\n",
    "# g.edges['gene_2_que_cell'].data['train_mask'] = torch.zeros(n_gene_2_que_cell, dtype=torch.bool).bernoulli(0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with gzip.open('Fetal-Brain3_dge.txt.gz', 'rb') as f:\n",
    "#     file_content = f.read()\n",
    "#     data = StringIO(str(file_content, 'utf-8'))\n",
    "# Brain_3_X = pd.read_csv(data)\n",
    "# print(f'Brain 3 has {Brain_3_X.shape[0]} genes and {Brain_3_X.shape[1]-1} cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2904, 13993)\n",
      "(3920, 13993)\n"
     ]
    }
   ],
   "source": [
    "with open('Brain_3_feature.pkl', 'rb') as f:\n",
    "\tBrain_3_feature = pickle.load(f)\n",
    "print(Brain_3_feature.shape)\n",
    "\n",
    "with open('Brain_4_feature.pkl', 'rb') as f:\n",
    "\tBrain_4_feature = pickle.load(f)\n",
    "print(Brain_4_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of ref cells: 2904\n",
      "number of que cells: 3920\n"
     ]
    }
   ],
   "source": [
    "print('number of ref cells:', n_ref_cell)\n",
    "print('number of que cells:', n_que_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2904, 50)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=50)\n",
    "Brain_3_comp = pca.fit_transform(Brain_3_feature)\n",
    "Brain_3_comp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3920, 50)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=50)\n",
    "Brain_4_comp = pca.fit_transform(Brain_4_feature)\n",
    "Brain_4_comp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.nodes['ref_cell'].data['feature'] = torch.tensor(Brain_3_comp)\n",
    "g.nodes['que_cell'].data['feature'] = torch.tensor(Brain_4_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('inter_gene_list.pkl', 'rb') as f:\n",
    "\tinter_gene_list = pickle.load(f)\n",
    "\n",
    "inter_gene_list = sorted(inter_gene_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./gene_sets/msigdb_v7.4_GMTs/h.all.v7.4.entrez.gmt') as gmt:\n",
    "    gene_list = gmt.read()\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "gene_str = str(gene_list)\n",
    "gene_list = gene_str.split()\n",
    "\n",
    "gene_sets_entrez = defaultdict(list)\n",
    "\n",
    "# print(gene_list[:100])\n",
    "indicator = 0\n",
    "for ele in gene_list:\n",
    "    if not ele.isnumeric() and indicator == 1:\n",
    "        indicator = 0\n",
    "        continue\n",
    "    if not ele.isnumeric() and indicator == 0:\n",
    "        indicator = 1\n",
    "        gene_set_name = ele\n",
    "    else:\n",
    "        gene_sets_entrez[gene_set_name].append(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./gene_sets/msigdb_v7.4_GMTs/h.all.v7.4.symbols.gmt') as gmt:\n",
    "    gene_list = gmt.read()\n",
    "\n",
    "gene_str = str(gene_list)\n",
    "gene_list = gene_str.split()\n",
    "\n",
    "gene_sets_symbols = defaultdict(list)\n",
    "\n",
    "# print(gene_list[:100])\n",
    "for ele in gene_list:\n",
    "    if ele in gene_sets_entrez:\n",
    "        gene_set_name = ele\n",
    "    elif not ele.startswith( 'http://' ):\n",
    "        gene_sets_symbols[gene_set_name].append(ele)\n",
    "\n",
    "# print(list(gene_sets_symbols.items())[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_gene_dict = {}\n",
    "for i, ele in enumerate(inter_gene_list):\n",
    "\tinter_gene_dict[ele] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5484, 890, 7345, 5193, 1900, 1804, 6265, 4838, 5707, 8276, 13422, 5171, 5483, 3460, 5282, 1127, 8544, 11280, 7524, 12431, 1285, 3314, 6335, 3726, 3773, 10554, 3458, 12316, 5594, 7344, 8890, 7523, 5458, 1807, 1803, 9183, 3322, 3462, 5192, 9218, 2121, 9332, 7348, 7525, 8147, 5195, 4408, 4325, 8328, 1166, 3459, 11274, 10948, 8825, 7342, 12474, 12043, 9219, 1176, 6035, 1884, 5320, 7035, 10731, 12333, 7120, 4206, 8401, 5179, 1896, 5292, 3440, 8083, 1809, 5216, 11417, 1286, 4326, 1284, 6432, 13015, 1993, 11775, 5207, 5280, 12673, 5392, 4204, 7707, 9292, 7377, 13307, 8337, 10467, 2588, 4632, 8364, 8869, 201, 5699, 6383, 2014, 12517, 5854, 11964, 9407, 1052, 3170, 7986, 11202, 8298, 3021, 1817, 3000, 12318, 1831, 4277, 1841, 12561, 1056, 7337, 4205, 8056, 7331, 942, 5290, 21, 4911, 1133, 5402, 10945, 2015, 11089, 12334, 7834, 4138, 3402, 3472, 3329, 8019, 4423, 5704, 12315, 10666, 7025]\n",
      "[8101, 8011, 4381, 8084, 450, 3602, 8103, 7217, 4981, 451, 4609, 7028, 10939, 7784, 306, 7785, 3601, 8086, 396, 3859, 8083, 13015, 1209, 12402, 3699, 5585, 1825, 5851, 4791, 4352, 1166, 5483, 6077, 4390, 8501, 6265, 2965, 10945, 7342, 4204, 9178, 4980, 2231, 4333, 13203, 11548, 13588, 1284, 8324, 2614, 13029, 5472, 3762, 3773, 8013, 566, 12853, 3703, 3603, 8401, 5028, 8099, 2202, 12245, 1107, 890, 1675, 495, 4600, 7221, 5402, 10451, 4303, 10554, 5193, 8276, 5823, 10416, 10332, 13422, 3454, 5191, 1993, 9462, 3314, 6629, 8558, 3273, 3300, 5097, 7522, 5707, 4601, 1545, 4915, 8544, 8104, 8217, 8627, 7116, 1994, 12055, 6943, 989, 6946, 10553, 12043, 581, 8090, 2964, 8657, 10988, 2819, 3441, 2491, 5708, 2203, 12399, 6213, 1126, 4394, 5727, 10499, 10892, 10552, 1664, 13022, 4217, 7997, 1042, 10947, 3440, 4484, 201, 7826, 2936, 10801, 8270, 12421, 8145, 7046, 1995, 4674, 5134, 7285, 12396, 13224, 6323, 405, 11922, 5683, 2409, 4598, 4872, 5299, 7172, 3725, 10606, 4206, 11960]\n"
     ]
    }
   ],
   "source": [
    "# save each gene sets in a list\n",
    "gene_sets = []\n",
    "for gene_set in gene_sets_symbols:\n",
    "\ttemp = []\n",
    "\tfor gene in gene_sets_symbols[gene_set]:\n",
    "\t\tif gene in inter_gene_dict:\n",
    "\t\t\ttemp.append(inter_gene_dict[gene])\n",
    "\tgene_sets.append(temp)\n",
    "\n",
    "print(gene_sets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Graph before gene sets added:', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene_1: [5484, 5484, 5484, 5484, 5484]\n",
      "gene_2: [890, 7345, 5193, 1900, 1804]\n"
     ]
    }
   ],
   "source": [
    "for gene_set in gene_sets:\n",
    "\tcomb = combinations(gene_set, 2)\n",
    "\tgene_1 = [ele[0] for ele in comb]\n",
    "\tgene_2 = [ele[1] for ele in comb]\n",
    "\tg.add_edges(torch.tensor(gene_1), torch.tensor(gene_2), etype='interaction')\n",
    "\tg.add_edges(torch.tensor(gene_2), torch.tensor(gene_1), etype='interaction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "DGLError",
     "evalue": "Edge type \"interaction\" does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_525416/1155678024.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgene_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgene_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'interaction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/Dgl_07/lib/python3.9/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36madd_edges\u001b[0;34m(self, u, v, data, etype)\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \u001b[0mu_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_canonical_etype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m         \u001b[0;31m# if end nodes of adding edges does not exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m# use add_nodes to add new nodes first.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Dgl_07/lib/python3.9/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36mto_canonical_etype\u001b[0;34m(self, etype)\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_etype2canonical\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mDGLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Edge type \"{}\" does not exist.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m                 raise DGLError('Edge type \"%s\" is ambiguous. Please use canonical edge type '\n",
      "\u001b[0;31mDGLError\u001b[0m: Edge type \"interaction\" does not exist."
     ]
    }
   ],
   "source": [
    "print('Graph after gene sets added:', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Heterograph Conv model\n",
    "class RGCN(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, rel_names):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = dglnn.HeteroGraphConv({\n",
    "            rel: dglnn.GraphConv(in_feats, hid_feats)\n",
    "            for rel in rel_names}, aggregate='sum')\n",
    "        self.conv2 = dglnn.HeteroGraphConv({\n",
    "            rel: dglnn.GraphConv(hid_feats, out_feats)\n",
    "            for rel in rel_names}, aggregate='sum')\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        # inputs are features of nodes\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = {k: F.relu(v) for k, v in h.items()}\n",
    "        h = self.conv2(graph, h)\n",
    "        return h\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RGCN(input_feature, 25, out_feature, g.etypes)\n",
    "\n",
    "gene_feats = g.nodes['gene'].data['feature']\n",
    "ref_cell_feats = g.nodes['ref_cell'].data['feature']\n",
    "que_cell_feats = g.nodes['que_cell'].data['feature']\n",
    "\n",
    "ref_cell_2_gene_feats = g.edges['ref_cell_2_gene'].data['feature']\n",
    "gene_2_ref_cell_feats = g.edges['gene_2_ref_cell'].data['feature']\n",
    "que_cell_2_gene_feats = g.edges['que_cell_2_gene'].data['feature']\n",
    "gene_2_que_cell_feats = g.edges['gene_2_que_cell'].data['feature']\n",
    "\n",
    "ref_cell_mask = g.nodes['ref_cell'].data['train_mask']\n",
    "que_cell_mask = g.nodes['que_cell'].data['train_mask']\n",
    "# how about validation mask?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use all the node and edge features\n",
    "node_edge_features = {'gene': gene_feats, 'ref_cell': ref_cell_feats, 'que_cell': que_cell_feats, 'ref_cell_2_gene': ref_cell_2_gene_feats,\n",
    "                 'gene_2_ref_cell': gene_2_ref_cell_feats, 'que_cell_2_gene': que_cell_2_gene_feats, 'gene_2_que_cell': gene_2_que_cell_feats}\n",
    "\n",
    "embedding = model(g, node_edge_features)\n",
    "               \n",
    "gene_embedding = embedding['gene']\n",
    "ref_cell_embedding = embedding['ref_cell']\n",
    "que_cell_embedding = embedding['que_cell']\n",
    "# print('length of embedding:', len(embedding))\n",
    "# print('embedding:', embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only node features\n",
    "# node_features = {'gene': gene_feats, 'ref_cell': ref_cell_feats, 'que_cell': que_cell_feats}\n",
    "\n",
    "# embedding = model(g, node_features)\n",
    "               \n",
    "# gene_embedding = embedding['gene']\n",
    "# ref_cell_embedding = embedding['ref_cell']\n",
    "# que_cell_embedding = embedding['que_cell']\n",
    "# print('length of embedding:', len(embedding))\n",
    "# print('embedding:', embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_cell_feats = ref_cell_feats[ref_cell_mask]\n",
    "que_cell_feats = que_cell_feats[que_cell_mask]\n",
    "\n",
    "true_ref_cell_dis_matrix = euclidean_distances(ref_cell_feats, ref_cell_feats)\n",
    "true_que_cell_dis_matrix = euclidean_distances(que_cell_feats, que_cell_feats)\n",
    "\n",
    "true_ref_cell_dis_matrix = torch.from_numpy(true_ref_cell_dis_matrix)\n",
    "true_que_cell_dis_matrix = torch.from_numpy(true_que_cell_dis_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_ref_cell_dis_matrix = true_ref_cell_dis_matrix.to(device)\n",
    "# true_que_cell_dis_matrix = true_que_cell_dis_matrix.to(device)\n",
    "\n",
    "# print(true_ref_cell_dis_matrix.shape)\n",
    "# print(true_que_cell_dis_matrix.shape)\n",
    "\n",
    "# need to change the evaluation to something else\n",
    "# how to calculat the similarity matrix between cells in high dimension?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, graph, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(graph, features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Traininig...')\n",
    "for epoch in range(10000):\n",
    "    model.train()\n",
    "    pred = model(g, node_edge_features)\n",
    "    # compute loss\n",
    "    pred_ref_cell_feats = pred['ref_cell']#.cpu().detach().numpy()\n",
    "    # print('pred ref cell feature shape:', pred_ref_cell_feats.shape)\n",
    "    pred_que_cell_feats = pred['que_cell']#.cpu().detach().numpy()\n",
    "    # print('pred que cell feature shape:', pred_que_cell_feats.shape)\n",
    "    \n",
    "    train_pred_ref_cell_feats = pred_ref_cell_feats[ref_cell_mask]\n",
    "    train_pred_que_cell_feats = pred_que_cell_feats[que_cell_mask]\n",
    "    \n",
    "#     val_pred_ref_cell_feats = pred_ref_cell_feats[1-ref_cell_mask]\n",
    "#     val_pred_que_cell_feats = pred_que_cell_feats[1-que_cell_mask]\n",
    "    # print('train_pred_ref_cell_feats:', train_pred_ref_cell_feats.shape)\n",
    "\n",
    "    # print('train_pred_ref_cell_feats:', type(train_pred_ref_cell_feats), 'true_ref_cell_dis_matrix', type(true_ref_cell_dis_matrix))\n",
    "\n",
    "    pred_ref_cell_dis_matrix = torch.cdist(train_pred_ref_cell_feats, train_pred_ref_cell_feats, p=2)\n",
    "    pred_que_cell_dis_matrix = torch.cdist(train_pred_que_cell_feats, train_pred_que_cell_feats, p=2)\n",
    "    \n",
    "    # print('pred_ref_cell_dis_matrix:', pred_ref_cell_dis_matrix.shape, 'true_ref_cell_dis_matrix:', true_ref_cell_dis_matrix.shape)\n",
    "\n",
    "    # pred_ref_cell_dis_matrix = euclidean_distances(pred_ref_cell_feats, pred_ref_cell_feats)\n",
    "    # pred_que_cell_dis_matrix = euclidean_distances(pred_que_cell_feats, pred_que_cell_feats)\n",
    "    \n",
    "    # print(pred_ref_cell_dis_matrix.shape, true_ref_cell_dis_matrix.shape)\n",
    "    # print(pred_que_cell_dis_matrix.shape, true_que_cell_dis_matrix.shape)\n",
    "    # loss_1 = loss_func(pred_ref_cell_dis_matrix, true_ref_cell_dis_matrix)\n",
    "    # print(loss_1)\n",
    "    loss = loss_func(pred_ref_cell_dis_matrix, true_ref_cell_dis_matrix) + loss_func(pred_que_cell_dis_matrix, true_que_cell_dis_matrix)\n",
    "\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print('epoch: ', epoch, 'train_loss:', loss.item())\n",
    "\n",
    "    # Save model if necessary.  Omitted in the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16fdec4dbab4f6f8d225df5cc1745ef0c64e10a3312a12d8f37d4c1010a81ff5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('Dgl_07': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
